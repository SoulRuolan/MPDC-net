{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b77e86-678c-40de-9958-479f816d3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load train_dcnet_acdc.py\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn.modules.loss import CrossEntropyLoss,KLDivLoss,BCELoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from dataloaders.dataset import (BaseDataSets, RandomGenerator, TwoStreamBatchSampler)\n",
    "from networks.net_factory import net_factory\n",
    "from utils import losses, ramps, val_2d\n",
    "\n",
    "def get_current_consistency_weight(epoch):\n",
    "    # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "    return args.consistency * ramps.sigmoid_rampup(epoch, args.consistency_rampup)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--root_path', type=str, default='../data/ACDC', help='Name of Experiment')\n",
    "parser.add_argument('--exp', type=str, default='DCNet', help='experiment_name')\n",
    "parser.add_argument('--model', type=str, default='mcnet_kd', help='model_name')\n",
    "parser.add_argument('--max_iterations', type=int, default=50000, help='maximum epoch number to train')\n",
    "parser.add_argument('--batch_size', type=int, default=24, help='batch_size per gpu')\n",
    "parser.add_argument('--deterministic', type=int, default=1, help='whether use deterministic training')\n",
    "parser.add_argument('--base_lr', type=float, default=0.01, help='segmentation network learning rate')\n",
    "parser.add_argument('--patch_size', type=list, default=[256, 256], help='patch size of network input')\n",
    "parser.add_argument('--seed', type=int, default=1337, help='random seed')\n",
    "parser.add_argument('--num_classes', type=int, default=4, help='output channel of network')\n",
    "parser.add_argument('--labeled_bs', type=int, default=12, help='labeled_batch_size per gpu')\n",
    "parser.add_argument('--labeled_num', type=int, default=7, help='labeled data')\n",
    "parser.add_argument('--gpu', type=str, default='0', help='GPU to use')\n",
    "parser.add_argument('--consistency', type=float, default=0.1, help='consistency')\n",
    "parser.add_argument('--consistency_rampup', type=float, default=200.0, help='consistency_rampup')\n",
    "parser.add_argument('--temperature', type=float, default=0.1, help='temperature of sharpening')\n",
    "parser.add_argument('--lamda', type=float, default=1, help='weight to balance all losses')\n",
    "parser.add_argument('--beta', type=float,  default=0.3, help='balance factor to control regional and sdm loss')\n",
    "parser.add_argument('--temp', default=1, type=float)\n",
    "\n",
    "parser.add_argument('--device_cpu', default=\"cpu\", type=str, help='use cpu')\n",
    "parser.add_argument('--device_gpu', default=\"cuda\", type=str, help='use gpu')\n",
    "parser.add_argument('--model_save_path', default=\"/root/autodl-tmp/Model/test\", type=str, help='Save Path of Model')\n",
    "parser.add_argument('--data_path', type=str, default='/root/autodl-tmp/Database/ACDC/h5py/', help='Path of Data')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(args=[])\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "device = torch.device(args.device_gpu)\n",
    "\n",
    "def patients_to_slices(dataset, patiens_num):\n",
    "    ref_dict = None\n",
    "    if \"ACDC\" in dataset:\n",
    "        ref_dict = {\"1\": 34, \"3\": 68, \"7\": 136,\n",
    "                    \"14\": 256, \"21\": 396, \"28\": 512, \"35\": 664, \"70\": 1312}\n",
    "    elif \"Prostate\":\n",
    "        ref_dict = {\"2\": 47, \"4\": 111, \"7\": 191,\n",
    "                    \"11\": 306, \"14\": 391, \"18\": 478, \"35\": 940}\n",
    "    elif \"Pulyp\" in dataset:\n",
    "        ref_dict = {\"2\": 47, \"3\": 51, \"7\": 102,\n",
    "                    \"11\": 306, \"14\": 203, \"28\": 405, \"35\": 940, \"70\": 1015}\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "    return ref_dict[str(patiens_num)]\n",
    "\n",
    "def train(args, snapshot_path):\n",
    "    base_lr = args.base_lr\n",
    "    labeled_bs = args.labeled_bs\n",
    "    num_classes = args.num_classes\n",
    "    max_iterations = args.max_iterations\n",
    "    \n",
    "    def create_model(ema=False):\n",
    "        model = net_factory(net_type=args.model, in_chns=1, class_num=num_classes)\n",
    "        print(torch.cuda.is_available())\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "        model = model.to(device)\n",
    "        if ema:\n",
    "            for param in model.parameters():\n",
    "                param.detach_()\n",
    "        return model\n",
    "    \n",
    "    model = create_model()\n",
    "\n",
    "    def worker_init_fn(worker_id):\n",
    "        random.seed(args.seed + worker_id)\n",
    "\n",
    "    db_train = BaseDataSets(base_dir=args.data_path,\n",
    "                            split=\"train\",\n",
    "                            num=None,\n",
    "                            transform=transforms.Compose([\n",
    "                                RandomGenerator(args.patch_size)\n",
    "                            ]))\n",
    "    db_val = BaseDataSets(base_dir=args.data_path, split=\"val\")\n",
    "    total_slices = len(db_train)\n",
    "\n",
    "    labeled_slice = patients_to_slices(args.data_path, args.labeled_num)\n",
    "    print(\"Total silices is: {}, labeled slices is: {}\".format(total_slices, labeled_slice))\n",
    "    labeled_idxs = list(range(0, labeled_slice))\n",
    "    unlabeled_idxs = list(range(labeled_slice, total_slices))\n",
    "    batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, args.batch_size,\n",
    "                                          args.batch_size - args.labeled_bs)\n",
    "    trainloader = DataLoader(db_train, batch_sampler=batch_sampler, num_workers=4, pin_memory=True,\n",
    "                             worker_init_fn=worker_init_fn)\n",
    "    model.train()\n",
    "\n",
    "    valloader = DataLoader(db_val, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0001)\n",
    "    ce_loss = CrossEntropyLoss()\n",
    "\n",
    "    mse_criterion = losses.mse_loss()\n",
    "    criterion_att = losses.Attention()\n",
    "\n",
    "    dice_loss = losses.DiceLoss(n_classes=num_classes)\n",
    "\n",
    "    writer = SummaryWriter(snapshot_path + '/log')\n",
    "    logging.info(\"{} iterations per epoch\".format(len(trainloader)))\n",
    "\n",
    "    iter_num = 0\n",
    "    max_epoch = max_iterations // len(trainloader) + 1\n",
    "    best_performance = 0.0\n",
    "    lr_ = base_lr\n",
    "    iterator = tqdm(range(max_epoch), ncols=70)\n",
    "    cur_threshold = 1 / num_classes\n",
    "    \n",
    "    for _ in iterator:\n",
    "        for _, sampled_batch in enumerate(trainloader):\n",
    "            volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "            volume_batch, label_batch = volume_batch.to(device), label_batch.to(device)\n",
    "            output1, output2, output3, encoder_features, decoder_features1, encoder_features_2, decoder_features2 = model(volume_batch)           \n",
    "            loss_seg_dice = 0\n",
    "\n",
    "            output1_soft = F.softmax(output1, dim=1)\n",
    "            output2_soft = F.softmax((-1 * output2), dim=1)\n",
    "            output3_soft = F.softmax(output3, dim=1)\n",
    "            \n",
    "            output1_soft0 = F.softmax(output1 / 0.5, dim=1)\n",
    "            output2_soft0 = F.softmax((-1 * (output2 / 0.5)), dim=1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                max_values1, _ = torch.max(output1_soft, dim=1)\n",
    "                max_values2, _ = torch.max(output2_soft, dim=1)\n",
    "                percent = (iter_num + 1) / max_iterations\n",
    "\n",
    "                cur_threshold1 = (1 - percent) * cur_threshold + percent * max_values1.mean()\n",
    "                cur_threshold2 = (1 - percent) * cur_threshold + percent * max_values2.mean()\n",
    "                mean_max_values = min(max_values1.mean(), max_values2.mean())\n",
    "\n",
    "                cur_threshold = min(cur_threshold1, cur_threshold2)\n",
    "                cur_threshold = torch.clip(cur_threshold, 0.25, 0.95)\n",
    "\n",
    "            mask_high = (output1_soft > cur_threshold) & (output2_soft > cur_threshold)\n",
    "            mask_non_similarity = (mask_high == False)\n",
    "\n",
    "            new_output1_soft = torch.mul(mask_non_similarity, output1_soft)\n",
    "            new_output2_soft = torch.mul(mask_non_similarity, output2_soft)\n",
    "\n",
    "            high_output1 = torch.mul(mask_high, output1)\n",
    "            high_output2 = torch.mul(mask_high, -1 * output2)\n",
    "            high_output1_soft = torch.mul(mask_high, output1_soft)\n",
    "            high_output2_soft = torch.mul(mask_high, output2_soft)\n",
    "            \n",
    "            output1_soft_pseudo = torch.argmax(output1_soft, dim=1)\n",
    "            output2_soft_pseudo = torch.argmax(output2_soft, dim=1)\n",
    "            output3_soft_pseudo = torch.argmax(output3_soft, dim=1)\n",
    "            pseudo_high_output1 = torch.argmax(high_output1_soft, dim=1)\n",
    "            pseudo_high_output2 = torch.argmax(high_output2_soft, dim=1)\n",
    "\n",
    "            max_output1_indices = new_output1_soft > new_output2_soft\n",
    "\n",
    "            max_output1_value0 = torch.mul(max_output1_indices, output1_soft0)\n",
    "            min_output2_value0 = torch.mul(max_output1_indices, output2_soft0)\n",
    "\n",
    "            max_output2_indices = new_output2_soft > new_output1_soft\n",
    "\n",
    "            max_output2_value0 = torch.mul(max_output2_indices, output2_soft0)\n",
    "            min_output1_value0 = torch.mul(max_output2_indices, output1_soft0)\n",
    "\n",
    "            loss_dc0 = 0\n",
    "            loss_cer = 0\n",
    "            loss_at_kd = 0.0\n",
    "            \n",
    "            # feature consistency loss\n",
    "            loss_at_kd += criterion_att(encoder_features, decoder_features1)        \n",
    "            loss_at_kd += criterion_att(encoder_features_2, decoder_features2)\n",
    "            \n",
    "            # direction consistency loss\n",
    "            loss_dc0 += mse_criterion(max_output1_value0.detach(), min_output2_value0)\n",
    "            loss_dc0 += mse_criterion(max_output2_value0.detach(), min_output1_value0)\n",
    "            \n",
    "            # supervised Loss\n",
    "            loss_seg_dice += dice_loss(output1_soft[:labeled_bs, ...], label_batch[:labeled_bs].unsqueeze(1))\n",
    "            loss_seg_dice += dice_loss(output2_soft[:labeled_bs, ...], label_batch[:labeled_bs].unsqueeze(1))\n",
    "            loss_seg_dice += dice_loss(output3_soft[:labeled_bs, ...], label_batch[:labeled_bs].unsqueeze(1))\n",
    "            \n",
    "            # cross pseudo supervised Loss\n",
    "            if mean_max_values >= 0.95:\n",
    "                loss_cer += ce_loss(output1, output3_soft_pseudo.long().detach())\n",
    "                loss_cer += ce_loss(output3, output1_soft_pseudo.long().detach())\n",
    "            \n",
    "                loss_cer += ce_loss((-1 * output2), output3_soft_pseudo.long().detach())\n",
    "                loss_cer += ce_loss(output3, output2_soft_pseudo.long().detach())\n",
    "            \n",
    "                loss_cer += ce_loss((-1 * output2), output1_soft_pseudo.long().detach())\n",
    "                loss_cer += ce_loss(output1, output2_soft_pseudo.long().detach())\n",
    "                \n",
    "            else:\n",
    "                loss_cer += ce_loss(high_output1, pseudo_high_output2.long().detach())\n",
    "                loss_cer += ce_loss(high_output2, pseudo_high_output1.long().detach())\n",
    "         \n",
    "            consistency_weight = get_current_consistency_weight(iter_num // 150)\n",
    "            supervised_loss = loss_seg_dice\n",
    "            \n",
    "            # total Loss\n",
    "            loss = supervised_loss + (1-consistency_weight) * (1000 * loss_at_kd) + consistency_weight * (1000 * loss_dc0 ) + 0.3 * loss_cer\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            iter_num = iter_num + 1\n",
    "            logging.info('iteration %d : loss : %03f,  loss_seg_dice: %03f, loss_at_kd: %03f, loss_dc0: %03f, cur_threshold: %03f, '\n",
    "                         'loss_cer: %03f, consistency_weight: %03f, mean_max_values: %03f' % (\n",
    "            iter_num, loss, loss_seg_dice, loss_at_kd, loss_dc0, cur_threshold, loss_cer, consistency_weight, mean_max_values))\n",
    "\n",
    "            if iter_num % 20 == 0:\n",
    "                image = volume_batch[1, 0:1, :, :]\n",
    "                writer.add_image('train/Image', image, iter_num)\n",
    "                output = torch.argmax(torch.softmax(output1, dim=1), dim=1, keepdim=True)\n",
    "                writer.add_image('train/Prediction', output[1, ...] * 50, iter_num)\n",
    "                labs = label_batch[1, ...].unsqueeze(0) * 50\n",
    "                writer.add_image('train/GroundTruth', labs, iter_num)\n",
    "\n",
    "            if iter_num > 0 and iter_num % 200 == 0:\n",
    "                model.eval()\n",
    "                metric_list = 0.0\n",
    "                for _, sampled_batch in enumerate(valloader):\n",
    "                    metric_i = val_2d.test_single_volume(sampled_batch[\"image\"], sampled_batch[\"label\"], model,\n",
    "                                                         classes=num_classes)\n",
    "                    metric_list += np.array(metric_i)\n",
    "                metric_list = metric_list / len(db_val)\n",
    "                for class_i in range(num_classes - 1):\n",
    "                    writer.add_scalar('info/val_{}_dice'.format(class_i + 1), metric_list[class_i, 0], iter_num)\n",
    "                    writer.add_scalar('info/val_{}_hd95'.format(class_i + 1), metric_list[class_i, 1], iter_num)\n",
    "\n",
    "                performance = np.mean(metric_list, axis=0)[0]\n",
    "\n",
    "                mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
    "                writer.add_scalar('info/val_mean_dice', performance, iter_num)\n",
    "                writer.add_scalar('info/val_mean_hd95', mean_hd95, iter_num)\n",
    "\n",
    "                if performance > best_performance:\n",
    "                    best_performance = performance\n",
    "                    save_mode_path = os.path.join(snapshot_path,\n",
    "                                                  'iter_{}_dice_{}.pth'.format(iter_num, round(best_performance, 4)))\n",
    "                    save_best_path = os.path.join(snapshot_path, '{}_best_model.pth'.format(args.model))\n",
    "                    torch.save(model.state_dict(), save_mode_path)\n",
    "                    torch.save(model.state_dict(), save_best_path)\n",
    "\n",
    "                logging.info('iteration %d : mean_dice : %f mean_hd95 : %f' % (iter_num, performance, mean_hd95))\n",
    "                model.train()\n",
    "                break\n",
    "        if iter_num >= max_iterations:\n",
    "            iterator.close()\n",
    "            break\n",
    "    writer.close()\n",
    "    return \"Training Finished!\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if args.deterministic:\n",
    "        cudnn.benchmark = False\n",
    "        cudnn.deterministic = True\n",
    "        random.seed(args.seed)\n",
    "        np.random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "        \n",
    "    snapshot_path = args.model_save_path + \"/fzyy_ACDC_{}_{}_{}_labeled\".format(args.model, args.exp, args.labeled_num)\n",
    "  \n",
    "    if not os.path.exists(snapshot_path):\n",
    "        os.makedirs(snapshot_path)\n",
    "    if os.path.exists(snapshot_path + '/code'):\n",
    "        shutil.rmtree(snapshot_path + '/code')\n",
    "    shutil.copytree('../code/', snapshot_path + '/code', shutil.ignore_patterns(['.git', '__pycache__']))\n",
    "\n",
    "    logging.basicConfig(filename=snapshot_path + \"/log.txt\", level=logging.INFO,\n",
    "                        format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
    "    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "    logging.info(str(args))\n",
    "    train(args, snapshot_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aaca70-5aac-4586-807b-3ed472edf0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
